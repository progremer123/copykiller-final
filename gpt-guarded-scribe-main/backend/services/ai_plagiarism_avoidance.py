#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""AI ê¸°ë°˜ í‘œì ˆ íšŒí”¼ ì„œë¹„ìŠ¤"""

import re
import random
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from difflib import SequenceMatcher

@dataclass
class PlagiarismAvoidanceResult:
    """í‘œì ˆ íšŒí”¼ ê²°ê³¼"""
    original_text: str
    rewritten_text: str
    similarity_reduction: float
    modifications: List[Dict]
    confidence_score: float
    
class AIPlagiarismAvoidance:
    """AI ê¸°ë°˜ í‘œì ˆ íšŒí”¼ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ë™ì˜ì–´ ì‚¬ì „ (í‘œì ˆ íšŒí”¼ìš©) - âœ… ìì—°ìŠ¤ëŸ½ê³  ì¶©ë¶„í•œ ë™ì˜ì–´
        self.avoidance_synonyms = {
            # í•™ìˆ  ìš©ì–´
            "ì—°êµ¬": ["ì¡°ì‚¬", "íƒêµ¬", "ë¶„ì„"],
            "ë¶„ì„": ["ê²€í† ", "í‰ê°€", "ì¡°ì‚¬"],
            "ê²°ê³¼": ["ì„±ê³¼", "ë„ì¶œ", "ê·€ê²°"],
            "ë°©ë²•": ["ë°©ì‹", "ìˆ˜ë‹¨", "ì ‘ê·¼ë²•"],
            "ì¤‘ìš”í•œ": ["ì£¼ìš”í•œ", "í•µì‹¬ì ì¸", "ì¤‘ëŒ€í•œ"],
            "ì¤‘ìš”í•˜ë‹¤": ["ì£¼ìš”í•˜ë‹¤", "í•µì‹¬ì´ë‹¤"],
            "íš¨ê³¼ì ì¸": ["íš¨ìœ¨ì ì¸", "ìœ íš¨í•œ"],
            "ë¬¸ì œ": ["ê³¼ì œ", "ì´ìŠˆ", "ì‚¬ì•ˆ"],
            "ê°œì„ ": ["í–¥ìƒ", "ë³´ì™„"],
            "ë°œì „": ["ì§„ë³´", "ì„±ì¥"],
            "ë³€í™”": ["ì „í™˜", "ë³€ë™"],
            
            # ì¼ë°˜ ìš©ì–´ (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì²´ì–´)
            "í™œìš©": ["ì´ìš©", "ì‚¬ìš©"],
            "í™œìš©ë˜ê³ ": ["ì´ìš©ë˜ê³ ", "ì‚¬ìš©ë˜ê³ "],
            "í™œìš©í•˜ì—¬": ["ì´ìš©í•˜ì—¬", "ì‚¬ìš©í•˜ì—¬"],
            "ë‹¤ì–‘í•œ": ["ì—¬ëŸ¬", "ê°ì¢…", "ë‹¤ìˆ˜ì˜"],
            "ë¶„ì•¼": ["ì˜ì—­", "ë¶€ë¬¸", "ë¶„ì•¼"],
            "ì—­í• ": ["ê¸°ëŠ¥", "ì—­í• "],
            "ë§¤ìš°": ["ìƒë‹¹íˆ", "ëŒ€ë‹¨íˆ"],
            "íŠ¹íˆ": ["íŠ¹ë³„íˆ", "ë¬´ì—‡ë³´ë‹¤"],
            "ì˜ë£Œ": ["ì˜í•™", "ì˜ë£Œ"],
            "êµìœ¡": ["í•™ìŠµ", "êµìœ¡"],
            "ê¸ˆìœµ": ["ì¬ë¬´", "ê¸ˆìœµ"],
            
            # ë™ì‚¬ (ê²¹ì¹˜ì§€ ì•ŠëŠ” ë™ì‚¬ë§Œ)
            "ì œì‹œí•˜ë‹¤": ["ì œì•ˆí•˜ë‹¤", "ë‚´ì„¸ìš°ë‹¤", "ì£¼ì¥í•˜ë‹¤", "í‘œëª…í•˜ë‹¤"],
            "ë‚˜íƒ€ë‚´ë‹¤": ["ë³´ì—¬ì£¼ë‹¤", "ë“œëŸ¬ë‚´ë‹¤", "í‘œí˜„í•˜ë‹¤", "ì‹œì‚¬í•˜ë‹¤"],
            "ì¦ê°€í•˜ë‹¤": ["ëŠ˜ì–´ë‚˜ë‹¤", "ìƒìŠ¹í•˜ë‹¤", "í™•ëŒ€ë˜ë‹¤", "ì¦ì§„ë˜ë‹¤"],
            "ê°ì†Œí•˜ë‹¤": ["ì¤„ì–´ë“¤ë‹¤", "ì¶•ì†Œë˜ë‹¤", "í•˜ë½í•˜ë‹¤", "ì €í•˜ë˜ë‹¤"],
            "ì˜í–¥ì„ ë¯¸ì¹˜ë‹¤": ["ì‘ìš©í•˜ë‹¤", "íš¨ê³¼ë¥¼ ì£¼ë‹¤", "ì˜í–¥ì„ ë¼ì¹˜ë‹¤"],
            
            # ì ‘ì†ì‚¬/ë¶€ì‚¬
            "ë˜í•œ": ["ë”ë¶ˆì–´", "ì•„ìš¸ëŸ¬", "ë™ì‹œì—", "ë¿ë§Œ ì•„ë‹ˆë¼", "ê²Œë‹¤ê°€"],
            "ê·¸ëŸ¬ë‚˜": ["í•˜ì§€ë§Œ", "ë‹¤ë§Œ", "ë°˜ë©´ì—", "ê·¸ëŸ¼ì—ë„", "ê·¸ë ‡ì§€ë§Œ"],
            "ë”°ë¼ì„œ": ["ê·¸ëŸ¬ë¯€ë¡œ", "ê·¸ëŸ° ì´ìœ ë¡œ", "ê²°ê³¼ì ìœ¼ë¡œ", "ê·¸ì— ë”°ë¼"],
            "íŠ¹íˆ": ["íŠ¹ë³„íˆ", "ë¬´ì—‡ë³´ë‹¤", "ì£¼ë¡œ", "ë”ìš±ì´"],
            "ë§¤ìš°": ["ê·¹íˆ", "ìƒë‹¹íˆ", "ëŒ€ë‹¨íˆ", "ì•„ì£¼"]
        }
        
        # ë¬¸ì¥ êµ¬ì¡° ë³€í™˜ íŒ¨í„´
        self.structure_patterns = [
            # ìˆ˜ë™íƒœ â†’ ëŠ¥ë™íƒœ
            {
                "pattern": r"(\w+)ì´ (\w+)ë˜ì—ˆë‹¤",
                "replacement": r"\2ê°€ \1ì„ ì´ë£¨ì—ˆë‹¤",
                "type": "passive_to_active"
            },
            # ëª…ì‚¬í˜• â†’ ë™ì‚¬í˜•
            {
                "pattern": r"(\w+)ì˜ (\w+)ì´ (\w+)í•˜ë‹¤",
                "replacement": r"\1ì´ \2í•˜ì—¬ \3í•˜ë‹¤",
                "type": "noun_to_verb"
            },
            # ì–´ìˆœ ë³€ê²½
            {
                "pattern": r"(\w+)ëŠ” (\w+)ì—ì„œ (\w+)í•˜ë‹¤",
                "replacement": r"\2ì—ì„œ \1ì´ \3í•˜ë‹¤",
                "type": "word_order_change"
            }
        ]
        
        # í‘œí˜„ ë‹¤ì–‘í™” íŒ¨í„´
        self.expression_variations = {
            "~ì´ë‹¤": ["~ë¼ê³  í•  ìˆ˜ ìˆë‹¤", "~ë¡œ íŒŒì•…ëœë‹¤", "~ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤"],
            "~ìˆë‹¤": ["~ì¡´ì¬í•œë‹¤", "~ë‚˜íƒ€ë‚œë‹¤", "~ê´€ì°°ëœë‹¤"],
            "~ë§ë‹¤": ["~í’ë¶€í•˜ë‹¤", "~ë‹¤ì–‘í•˜ë‹¤", "~ìƒë‹¹í•˜ë‹¤"],
            "~ì¤‘ìš”í•˜ë‹¤": ["~í•µì‹¬ì ì´ë‹¤", "~í•„ìˆ˜ì ì´ë‹¤", "~ê²°ì •ì ì´ë‹¤"]
        }
    
    def avoid_plagiarism(self, original_text: str, plagiarism_matches: List[Dict]) -> PlagiarismAvoidanceResult:
        """í‘œì ˆ ë¶€ë¶„ì„ AIë¡œ íšŒí”¼í•˜ì—¬ ì¬ì‘ì„±"""
        print(f"ğŸ›¡ï¸ AI í‘œì ˆ íšŒí”¼ ì‹œì‘: ì›ë³¸ {len(original_text)}ì, ë§¤ì¹˜ {len(plagiarism_matches)}ê°œ")
        
        # âœ… ë””ë²„ê·¸: ë§¤ì¹˜ ì •ë³´ ì¶œë ¥
        for i, match in enumerate(plagiarism_matches):
            print(f"  ë§¤ì¹˜ {i+1}: '{match.get('matched_text', '')[:30]}...' (ìœ ì‚¬ë„ {match.get('similarity_score', 0)}%)")
        
        modifications = []
        rewritten_text = original_text
        
        # 1. í‘œì ˆ ë§¤ì¹˜ëœ ë¶€ë¶„ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ìˆ˜ì • (ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¸ë±ìŠ¤ ìœ ì§€)
        for match in sorted(plagiarism_matches, key=lambda x: x.get('start_index', 0), reverse=True):
            matched_text = match.get('matched_text', '')
            start_idx = match.get('start_index', 0)
            end_idx = match.get('end_index', 0)
            similarity = match.get('similarity_score', 0)
            
            print(f"  ì²˜ë¦¬ ì¤‘: '{matched_text[:30]}...' (ìœ ì‚¬ë„ {similarity}%, ì„ê³„ê°’ 40)")
            
            # âœ… ì„ê³„ê°’ 40: ì¤‘ìœ„í—˜ ì´ìƒ ë¶€ë¶„ ìˆ˜ì • (ì ì ˆí•œ ê· í˜•)
            if matched_text and start_idx < end_idx and similarity > 40:
                # ì‹¤ì œ í‘œì ˆ ë°©ì§€ ë„êµ¬ì˜ ê³ ê¸‰ ì¬ì‘ì„± ê¸°ë²• ì‚¬ìš©
                rewritten_part = self._advanced_rewrite_section(matched_text, similarity)
                
                # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë¶€ë¶„ êµì²´
                try:
                    rewritten_text = (
                        rewritten_text[:start_idx] + 
                        rewritten_part + 
                        rewritten_text[end_idx:]
                    )
                    
                    modifications.append({
                        "type": "plagiarism_rewrite",
                        "original": matched_text,
                        "rewritten": rewritten_part,
                        "position": f"{start_idx}-{end_idx}",
                        "reason": f"ìœ ì‚¬ë„ {similarity:.1f}% íšŒí”¼",
                        "techniques": ["ë™ì˜ì–´ ì¹˜í™˜", "ë¬¸ì¥ êµ¬ì¡° ë³€ê²½", "í‘œí˜„ ë‹¤ì–‘í™”"]
                    })
                except Exception as e:
                    print(f"âš ï¸ ì¬ì‘ì„± ì˜¤ë¥˜: {e}")
                    continue
        
        # 2. ì „ì²´ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¶”ê°€ ë‹¤ì–‘í™”
        rewritten_text = self._apply_general_variations(rewritten_text, modifications)
        
        # 3. ìœ ì‚¬ë„ ê°ì†Œ ê³„ì‚° (ë” ì •í™•í•œ ê³„ì‚°)
        similarity_reduction = self._calculate_similarity_reduction(original_text, rewritten_text)
        
        # 4. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = self._calculate_confidence(modifications, similarity_reduction)
        
        result = PlagiarismAvoidanceResult(
            original_text=original_text,
            rewritten_text=rewritten_text,
            similarity_reduction=similarity_reduction,
            modifications=modifications,
            confidence_score=confidence_score
        )
        
        print(f"âœ… AI í‘œì ˆ íšŒí”¼ ì™„ë£Œ: {len(modifications)}ê°œ ë¶€ë¶„ ìˆ˜ì •, ìœ ì‚¬ë„ {similarity_reduction:.1f}% ê°ì†Œ")
        return result
    
    def _advanced_rewrite_section(self, text: str, similarity_score: float) -> str:
        """ê³ ê¸‰ í‘œì ˆ íšŒí”¼: ì‹¤ì œ ë„êµ¬ë“¤ì´ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•"""
        rewritten = text
        
        # ìœ ì‚¬ë„ì— ë”°ë¥¸ ê°•ë„ ì¡°ì ˆ
        intensity = min(similarity_score / 100.0, 1.0)
        
        print(f"  ğŸ“ ì›ë¬¸: {text[:50]}...")
        
        # âœ… 1ë‹¨ê³„: ì˜ë¯¸ ë³´ì¡´ íŒ¨ëŸ¬í”„ë ˆì´ì§• (ë¨¼ì € ì‹¤í–‰)
        rewritten = self._paraphrase_intelligently(rewritten)
        
        # 2ë‹¨ê³„: ë¬¸ì¥ êµ¬ì¡° ë³€í˜• (90% ì´ìƒì¼ ë•Œ í•„ìˆ˜)
        if intensity > 0.9 or similarity_score > 85:
            rewritten = self._restructure_sentence_fundamentally(rewritten)
            rewritten = self._change_voice_and_tense(rewritten)
        
        # âœ… 3ë‹¨ê³„: ê¸°ë³¸ ë™ì˜ì–´ êµì²´ (ë§ˆì§€ë§‰ì— ì‹¤í–‰í•˜ì—¬ ì¤‘ë³µ ë°©ì§€)
        rewritten = self._substitute_synonyms_aggressive(rewritten)
        
        # 4ë‹¨ê³„: ë¬¸ì¥ ë¶„í• /ê²°í•©
        if len(rewritten) > 30:
            rewritten = self._split_or_combine_sentences(rewritten, intensity)
        
        # 5ë‹¨ê³„: ë¬¸ë²•ì  ë³€í˜•
        rewritten = self._apply_grammatical_transformations(rewritten)
        
        # 6ë‹¨ê³„: ì¶”ê°€ í‘œí˜„ ë‹¤ì–‘í™”
        if intensity > 0.7:
            rewritten = self._diversify_expressions(rewritten)
        
        print(f"  âœï¸  ìˆ˜ì •ë³¸: {rewritten[:50]}...")
        
        return rewritten.strip()
    
    def _substitute_synonyms_aggressive(self, text: str) -> str:
        """ì ê·¹ì ì¸ ë™ì˜ì–´ êµì²´ (50% ì´ìƒ ë‹¨ì–´ ë³€ê²½)"""
        # âœ… ë¨¼ì € ëª¨ë“  êµì²´ ì‘ì—…ì„ ê³„íší•œ ë‹¤ìŒ í•œ ë²ˆì— ì ìš©
        replacements = []
        used_positions = set()
        
        # âœ… ê¸´ êµ¬ë¬¸ë¶€í„° ì²˜ë¦¬í•˜ë„ë¡ ì •ë ¬ (ê²¹ì¹˜ëŠ” êµì²´ ë°©ì§€)
        sorted_terms = sorted(self.avoidance_synonyms.items(), key=lambda x: len(x[0]), reverse=True)
        
        replaced_originals = set()  # âœ… ì´ë¯¸ êµì²´í•œ ì›ë³¸ ìš©ì–´ ì¶”ì 
        
        # ê° ì›ë³¸ ìš©ì–´ì— ëŒ€í•´ í…ìŠ¤íŠ¸ì—ì„œ ìœ„ì¹˜ë¥¼ ì°¾ê³  êµì²´ ê³„íš ìˆ˜ë¦½
        for original_term, synonyms in sorted_terms:
            # ì´ë¯¸ êµì²´í•œ ìš©ì–´ëŠ” ê±´ë„ˆë›°ê¸°
            if original_term in replaced_originals:
                continue
            
            start = 0
            while True:
                pos = text.find(original_term, start)
                if pos == -1:
                    break
                
                # ì´ë¯¸ êµì²´ ì˜ˆì •ì¸ ìœ„ì¹˜ì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
                overlaps = any(pos < end and pos + len(original_term) > start_pos 
                              for start_pos, end in used_positions)
                
                if not overlaps:
                    synonym = random.choice(synonyms)
                    replacements.append((pos, original_term, synonym))
                    used_positions.add((pos, pos + len(original_term)))
                    replaced_originals.add(original_term)
                    
                    # âœ… ì„ íƒí•œ ë™ì˜ì–´ê°€ ë‹¤ë¥¸ ì›ë³¸ ìš©ì–´ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ê±´ë„ˆë›°ë„ë¡ í‘œì‹œ
                    for other_term in self.avoidance_synonyms.keys():
                        if other_term in synonym or synonym in other_term:
                            replaced_originals.add(other_term)
                    
                    print(f"    - '{original_term}' â†’ '{synonym}'")
                    break  # ê° ìš©ì–´ë‹¹ 1ê°œë§Œ êµì²´
                
                start = pos + 1
        
        # ìœ„ì¹˜ ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ êµì²´ (ë’¤ì—ì„œë¶€í„° êµì²´í•´ì•¼ ì¸ë±ìŠ¤ê°€ ì•ˆ ê¼¬ì„)
        replacements.sort(key=lambda x: x[0], reverse=True)
        modified_text = text
        
        for pos, original, synonym in replacements:
            modified_text = modified_text[:pos] + synonym + modified_text[pos + len(original):]
        
        print(f"    ğŸ“Š ì´ {len(replacements)}ê°œ ë‹¨ì–´ êµì²´")
        return modified_text
    
    def _restructure_sentence_fundamentally(self, text: str) -> str:
        """ë¬¸ì¥ì˜ ê·¼ë³¸ì ì¸ êµ¬ì¡° ë³€ê²½"""
        # ì£¼ì–´-ëª©ì ì–´ ìˆœì„œ ë³€ê²½
        patterns = [
            (r'(.*?)ì´ (.*?)ì„ (.*?)í•œë‹¤', r'\2ì´ \1ì— ì˜í•´ \3ëœë‹¤'),  # ëŠ¥ë™â†’ìˆ˜ë™
            (r'(.*?)ëŠ” (.*?)ì´ë‹¤', r'\2ëŠ” \1ì´ íŠ¹ì§•ì´ë‹¤'),
            (r'(.*?)ë•Œë¬¸ì´ë‹¤', r'ê·¸ ì›ì¸ì€ \1ì— ìˆë‹¤'),
            (r'(.*?)í•  ìˆ˜ ìˆë‹¤', r'\1ì´ ê°€ëŠ¥í•˜ë‹¤'),
            (r'(.*?)í•´ì•¼ í•œë‹¤', r'\1ì´ í•„ìš”í•˜ë‹¤'),
        ]
        
        for pattern, replacement in patterns:
            if re.search(pattern, text):
                text = re.sub(pattern, replacement, text)
                print(f"    - ë¬¸ì¥ êµ¬ì¡° ë³€ê²½ ì ìš©")
                break
        
        return text
    
    def _change_voice_and_tense(self, text: str) -> str:
        """ì‹œì œ ë° ìŒì„± ë³€ê²½"""
        transformations = [
            ('í•œë‹¤', 'ì¼ì–´ë‚œë‹¤'),
            ('í•œë‹¤', 'ì§„í–‰ ì¤‘ì´ë‹¤'),
            ('ì´ë‹¤', 'ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤'),
            ('ìˆë‹¤', 'ì¡´ì¬í•œë‹¤'),
            ('í•  ìˆ˜ ìˆë‹¤', 'ê°€ëŠ¥ì„±ì´ ìˆë‹¤'),
            ('í•´ì•¼ í•œë‹¤', 'í•„ìˆ˜ì ì´ë‹¤'),
        ]
        
        for original, replacement in transformations:
            if original in text and random.choice([True, False]):
                text = text.replace(original, replacement, 1)
                print(f"    - ì‹œì œ/ìŒì„± ë³€ê²½: '{original}' â†’ '{replacement}'")
        
        return text
    
    def _paraphrase_intelligently(self, text: str) -> str:
        """ì˜ë¯¸ ë³´ì¡´ íŒ¨ëŸ¬í”„ë ˆì´ì§• - ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œë§Œ ì œí•œ"""
        paraphrases = {
            # âœ… ìì—°ìŠ¤ëŸ½ê³  ì˜ë¯¸ê°€ ìœ ì‚¬í•œ í‘œí˜„ë§Œ ì‚¬ìš©
            'í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤': 'ì´ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤',
            'í™œìš©ë˜ê³  ìˆëŠ”': 'ì´ìš©ë˜ê³  ìˆëŠ”',
            'ì—°êµ¬ì— ë”°ë¥´ë©´': 'ì¡°ì‚¬ ê²°ê³¼',
            'ê²°ë¡ ì ìœ¼ë¡œ': 'ìš”ì•½í•˜ë©´',
            'ì˜ˆë¥¼ ë“¤ì–´': 'ê°€ë ¹',
            'ì´ë¥¼ í†µí•´': 'ì´ë¡œì¨',
            'ë˜í•œ': 'ì•„ìš¸ëŸ¬',
            'ê·¸ëŸ¬ë‚˜': 'í•˜ì§€ë§Œ',
            'ë”°ë¼ì„œ': 'ê·¸ëŸ¬ë¯€ë¡œ',
        }
        
        # âœ… ê° íŒ¨ëŸ¬í”„ë ˆì´ì§• 1íšŒë§Œ ì ìš© (count=1)
        for phrase, replacement in paraphrases.items():
            if phrase in text:
                text = text.replace(phrase, replacement, 1)
                print(f"    - íŒ¨ëŸ¬í”„ë ˆì´ì§•: '{phrase}' â†’ '{replacement}'")
        
        return text
    
    def _split_or_combine_sentences(self, text: str, intensity: float) -> str:
        """ë¬¸ì¥ ë¶„í• /ê²°í•©"""
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        if len(sentences) >= 2:
            if intensity > 0.7 and random.choice([True, False]):
                # ë¬¸ì¥ ì¬ë°°ì—´
                if len(sentences) >= 3:
                    # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ë¬¸ì¥ ìœ ì§€, ë‚˜ë¨¸ì§€ ìˆœì„œ ë³€ê²½
                    middle = sentences[1:-1]
                    if len(middle) > 1:
                        random.shuffle(middle)
                        sentences = [sentences[0]] + middle + [sentences[-1]]
                    print(f"    - ë¬¸ì¥ ìˆœì„œ ì¬ë°°ì—´")
            
            # ì§§ì€ ë¬¸ì¥ë“¤ ê²°í•©
            combined_sentences = []
            for i in range(0, len(sentences), 2):
                if i + 1 < len(sentences):
                    combined = f"{sentences[i]} ê·¸ë¦¬ê³  {sentences[i+1]}"
                    combined_sentences.append(combined)
                else:
                    combined_sentences.append(sentences[i])
            
            text = ' '.join(combined_sentences)
        
        return text
    
    def _apply_grammatical_transformations(self, text: str) -> str:
        """ë¬¸ë²•ì  ë³€í˜•"""
        # ë¶€ì‚¬ ì¶”ê°€
        adverbs = ['ì‚¬ì‹¤ìƒ', 'ì‹¤ì§ˆì ìœ¼ë¡œ', 'ê¸°ë³¸ì ìœ¼ë¡œ', 'ê·¼ë³¸ì ìœ¼ë¡œ', 'ê¶ê·¹ì ìœ¼ë¡œ']
        
        # í˜•ìš©ì‚¬ ë³€ê²½
        adjective_changes = {
            'í°': 'ì£¼ìš”í•œ',
            'ì‘ì€': 'ë¯¸ë¯¸í•œ',
            'ì¢‹ì€': 'ê¸ì •ì ì¸',
            'ë‚˜ìœ': 'ë¶€ì •ì ì¸',
            'ë†’ì€': 'ìƒìœ„ì˜',
            'ë‚®ì€': 'í•˜ìœ„ì˜',
        }
        
        for adj, replacement in adjective_changes.items():
            if adj in text:
                text = text.replace(adj, replacement, 1)
                print(f"    - í˜•ìš©ì‚¬ ë³€ê²½: '{adj}' â†’ '{replacement}'")
        
        return text
    
    def _diversify_expressions(self, text: str) -> str:
        """í‘œí˜„ ë‹¤ì–‘í™”"""
        expressions = {
            'ìˆ˜ ìˆë‹¤': ['ê°€ëŠ¥í•˜ë‹¤', 'ëŠ¥ë ¥ì´ ìˆë‹¤', 'ì—¬ë ¥ì´ ìˆë‹¤'],
            'í•´ì•¼ í•œë‹¤': ['í•„ìš”í•˜ë‹¤', 'ìš”êµ¬ëœë‹¤', 'í•„ìˆ˜ì´ë‹¤'],
            'ì¤‘ìš”í•˜ë‹¤': ['ì¤‘ëŒ€í•˜ë‹¤', 'í•µì‹¬ì ì´ë‹¤', 'ê²°ì •ì ì´ë‹¤'],
            'ìˆë‹¤': ['ì¡´ì¬í•˜ë‹¤', 'ë‚˜íƒ€ë‚˜ë‹¤', 'ë³´ì´ë‹¤'],
        }
        
        for original, variations in expressions.items():
            if original in text and random.choice([True, False]):
                replacement = random.choice(variations)
                text = text.replace(original, replacement, 1)
                print(f"    - í‘œí˜„ ë‹¤ì–‘í™”: '{original}' â†’ '{replacement}'")
        
        return text
    
    def _rewrite_plagiarized_section(self, plagiarized_text: str, similarity_score: float) -> str:
        """í‘œì ˆëœ ì„¹ì…˜ì„ AIë¡œ ì¬ì‘ì„±"""
        rewritten = plagiarized_text
        
        # ìœ ì‚¬ë„ê°€ ë†’ì„ìˆ˜ë¡ ë” ì ê·¹ì ìœ¼ë¡œ ë³€ê²½
        intensity = min(similarity_score / 100.0, 1.0)
        
        # 1. ì ê·¹ì ì¸ ë™ì˜ì–´ êµì²´ (ì—¬ëŸ¬ ë‹¨ì–´ ë™ì‹œ ë³€ê²½)
        words = rewritten.split()
        modified_words = []
        changes_made = 0
        max_changes = max(2, int(len(words) * 0.3 * intensity))  # 30% ì´ìƒ ë‹¨ì–´ ë³€ê²½
        
        for word in words:
            # ë¶ˆìš©ì–´ ì œì™¸
            if word.lower() in ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ë¥¼', 'ì—', 'ì—ê²Œ', 'ì—ì„œ', 'ê³¼', 'ê·¸ë¦¬ê³ ', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œ']:
                modified_words.append(word)
            else:
                # ë™ì˜ì–´ë¡œ ë³€ê²½í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
                replaced = False
                for original, synonyms in self.avoidance_synonyms.items():
                    if word.lower() == original.lower() and changes_made < max_changes:
                        modified_words.append(random.choice(synonyms))
                        changes_made += 1
                        replaced = True
                        break
                if not replaced:
                    modified_words.append(word)
        
        rewritten = ' '.join(modified_words)
        
        # 2. ë¬¸ì¥ êµ¬ì¡° ë³€ê²½ (ëŠ¥ë™íƒœ â†” ìˆ˜ë™íƒœ, ì£¼ì–´ ìˆœì„œ ë³€ê²½)
        if intensity > 0.5:
            rewritten = self._transform_sentence_voice(rewritten)
            rewritten = self._reorder_clauses(rewritten)
        
        # 3. í‘œí˜„ ë‹¤ì–‘í™” (ì–´ë¯¸ ë³€ê²½, ì‹œì œ ë³€ê²½)
        if intensity > 0.6:
            rewritten = self._vary_expressions(rewritten)
        
        # 4. ë¬¸ì¥ ì¬êµ¬ì„± (ì ‘ì†ì‚¬ ë³€ê²½, ìˆ˜ì‹êµ¬ ìœ„ì¹˜ ë³€ê²½)
        if intensity > 0.7:
            rewritten = self._restructure_sentences(rewritten)
        
        return rewritten.strip()
    
    def _transform_sentence_voice(self, text: str) -> str:
        """ëŠ¥ë™íƒœì™€ ìˆ˜ë™íƒœ ë³€í™˜"""
        transformations = {
            r'([ê°€-í£]+?)ì´ ([ê°€-í£]+?)ì„ ([ê°€-í£]+?)í•œë‹¤': r'\1ì´ \2ì˜ ëŒ€ìƒì´ ë˜ì–´ \3ëœë‹¤',
            r'([ê°€-í£]+?)ì´ ([ê°€-í£]+?)ë¥¼ ([ê°€-í£]+?)í•œë‹¤': r'\1ì´ \2ì˜ ëŒ€ìƒì´ ë˜ì–´ \3ëœë‹¤',
            r'([ê°€-í£]+?)ì´ ([ê°€-í£]+?)ì— ([ê°€-í£]+?)í•œë‹¤': r'\2ì— \1ì— ì˜í•´ \3ì´ ì´ë£¨ì–´ì§„ë‹¤',
        }
        
        for pattern, replacement in transformations.items():
            if random.choice([True, False]):  # 50% í™•ë¥ ë¡œ ë³€í™˜
                text = re.sub(pattern, replacement, text)
        
        return text
    
    def _reorder_clauses(self, text: str) -> str:
        """ì ˆì˜ ìˆœì„œ ë³€ê²½"""
        clauses = re.split(r'([,;])', text)
        
        if len(clauses) >= 3:
            # ì ˆë“¤ì˜ ìˆœì„œë¥¼ ì„ê¸° (ì²« ì ˆì€ ìœ ì§€)
            first = clauses[0]
            middle = clauses[1:-1]
            
            if len(middle) > 4:  # ì¶©ë¶„í•œ ì ˆì´ ìˆìœ¼ë©´ ìˆœì„œ ë³€ê²½
                random.shuffle(middle[1::2])  # ì ˆë“¤ë§Œ ì„ê¸° (êµ¬ë¶„ì ìœ ì§€)
                text = first + ''.join(middle)
        
        return text
    
    def _vary_expressions(self, text: str) -> str:
        """í‘œí˜„ ë‹¤ì–‘í™” (ì–´ë¯¸, ì‹œì œ ë³€ê²½)"""
        variations = {
            'í•œë‹¤': ['í•  ìˆ˜ ìˆë‹¤', 'ì¼ì–´ë‚œë‹¤', 'ì§„í–‰ëœë‹¤', 'ì‹¤í–‰ëœë‹¤'],
            'ìˆë‹¤': ['ì¡´ì¬í•œë‹¤', 'ë‚˜íƒ€ë‚œë‹¤', 'ê´€ì°°ëœë‹¤', 'ë“œëŸ¬ë‚œë‹¤'],
            'ì´ë‹¤': ['ë¼ê³  í•  ìˆ˜ ìˆë‹¤', 'ë¡œ íŒŒì•…ëœë‹¤', 'ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤', 'ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤'],
            'ë§ë‹¤': ['í’ë¶€í•˜ë‹¤', 'ë‹¤ì–‘í•˜ë‹¤', 'ìƒë‹¹í•˜ë‹¤', 'ê´‘ë²”ìœ„í•˜ë‹¤'],
            'ì¤‘ìš”í•˜ë‹¤': ['í•µì‹¬ì ì´ë‹¤', 'í•„ìˆ˜ì ì´ë‹¤', 'ê²°ì •ì ì´ë‹¤', 'ì£¼ìš”í•˜ë‹¤'],
        }
        
        for original, options in variations.items():
            if original in text and random.choice([True, False]):  # 50% í™•ë¥ 
                replacement = random.choice(options)
                text = text.replace(original, replacement, 1)
        
        return text
    
    def _restructure_sentences(self, text: str) -> str:
        """ë¬¸ì¥ ì¬êµ¬ì„± (ì ‘ì†ì‚¬ ë³€ê²½, ìˆ˜ì‹êµ¬ ìœ„ì¹˜ ë³€ê²½)"""
        connectors = {
            'ê·¸ëŸ¬ë‚˜': ['í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ëŸ¬ë‚˜', 'ì˜¤íˆë ¤'],
            'ê·¸ë¦¬ê³ ': ['ë˜í•œ', 'ê·¸ë¦¬ê³ ', 'ë”ë¶ˆì–´', 'ì•„ìš¸ëŸ¬'],
            'ë•Œë¬¸ì—': ['ì¸í•´', 'ìœ¼ë¡œ ì¸í•´', 'ê²°ê³¼ë¡œ', 'ì´ìœ ë¡œ'],
            'ë˜í•œ': ['ê·¸ë¦¬ê³ ', 'ë”ìš±ì´', 'ë§ë¶™ì—¬', 'ì¶”ê°€ë¡œ'],
        }
        
        for original, replacements in connectors.items():
            if original in text and random.choice([True, False]):  # 50% í™•ë¥ 
                replacement = random.choice(replacements)
                text = text.replace(original, replacement, 1)
        
        return text
    
    def _apply_synonyms(self, text: str, max_changes: int = 3) -> str:
        """ë™ì˜ì–´ ì ìš©"""
        changes_made = 0
        
        for original, synonyms in self.avoidance_synonyms.items():
            if changes_made >= max_changes:
                break
                
            if original in text:
                synonym = random.choice(synonyms)
                text = text.replace(original, synonym, 1)  # ì²« ë²ˆì§¸ ë°œê²¬ë§Œ êµì²´
                changes_made += 1
        
        return text
    
    def _apply_structure_changes(self, text: str) -> str:
        """ë¬¸ì¥ êµ¬ì¡° ë³€ê²½"""
        for pattern_info in self.structure_patterns:
            pattern = pattern_info["pattern"]
            replacement = pattern_info["replacement"]
            
            if re.search(pattern, text):
                text = re.sub(pattern, replacement, text, count=1)
                break  # í•˜ë‚˜ì˜ íŒ¨í„´ë§Œ ì ìš©
        
        return text
    
    def _apply_expression_variations(self, text: str) -> str:
        """í‘œí˜„ ë‹¤ì–‘í™”"""
        for original, variations in self.expression_variations.items():
            if original in text:
                variation = random.choice(variations)
                text = text.replace(original, variation, 1)
        
        return text
    
    def _modify_sentence_structure(self, text: str) -> str:
        """ë¬¸ì¥ ë¶„í• /ê²°í•©ìœ¼ë¡œ êµ¬ì¡° ë³€ê²½"""
        sentences = re.split(r'[.!?]\s*', text.strip())
        
        if len(sentences) >= 2:
            # ëœë¤í•˜ê²Œ ë¬¸ì¥ ê²°í•© ë˜ëŠ” ë¶„í• 
            if random.choice([True, False]):
                # ë¬¸ì¥ ê²°í•©
                if len(sentences) >= 2:
                    combined = f"{sentences[0]}ì´ë©°, {sentences[1]}"
                    return combined + '. ' + '. '.join(sentences[2:])
            else:
                # ë¬¸ì¥ ë¶„í•  (ê¸¸ì€ ë¬¸ì¥ì„ ë‘˜ë¡œ ë‚˜ëˆ„ê¸°)
                for i, sentence in enumerate(sentences):
                    if len(sentence) > 50 and ',' in sentence:
                        parts = sentence.split(',', 1)
                        sentences[i] = parts[0].strip() + '.'
                        sentences.insert(i+1, parts[1].strip())
                        break
        
        return '. '.join(sentences) + '.'
    
    def _apply_general_variations(self, text: str, modifications: List[Dict]) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ì— ì¼ë°˜ì ì¸ ë‹¤ì–‘í™” ì ìš©"""
        # í‘œì ˆ ë¶€ë¶„ì´ ì•„ë‹Œ ê³³ì—ë„ ì•½ê°„ì˜ ë³€í™” ì ìš©
        variation_count = 0
        max_variations = 2
        
        for original, synonyms in list(self.avoidance_synonyms.items())[:10]:
            if variation_count >= max_variations:
                break
                
            if original in text:
                # ì´ë¯¸ ìˆ˜ì •ëœ ë¶€ë¶„ì€ ì œì™¸
                already_modified = any(original in mod.get('original', '') for mod in modifications)
                if not already_modified:
                    synonym = random.choice(synonyms)
                    text = text.replace(original, synonym, 1)
                    
                    modifications.append({
                        "type": "general_variation",
                        "original": original,
                        "rewritten": synonym,
                        "reason": "ì „ì²´ì  ë‹¤ì–‘í™”"
                    })
                    variation_count += 1
        
        return text
    
    def _calculate_similarity_reduction(self, original: str, rewritten: str) -> float:
        """ìœ ì‚¬ë„ ê°ì†Œìœ¨ ê³„ì‚°"""
        # SequenceMatcherë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = SequenceMatcher(None, original, rewritten).ratio()
        reduction = (1.0 - similarity) * 100.0
        return max(0.0, min(100.0, reduction))
    
    def _calculate_confidence(self, modifications: List[Dict], similarity_reduction: float) -> float:
        """ì¬ì‘ì„± ì‹ ë¢°ë„ ê³„ì‚°"""
        # ìˆ˜ì • ê°œìˆ˜ì™€ ìœ ì‚¬ë„ ê°ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        modification_score = min(len(modifications) * 10, 50)  # ìµœëŒ€ 50ì 
        similarity_score = min(similarity_reduction * 2, 50)   # ìµœëŒ€ 50ì 
        
        confidence = modification_score + similarity_score
        return max(0.0, min(100.0, confidence))
    
    def get_avoidance_statistics(self) -> Dict:
        """í‘œì ˆ íšŒí”¼ ì‹œìŠ¤í…œ í†µê³„"""
        return {
            "synonym_count": len(self.avoidance_synonyms),
            "structure_patterns": len(self.structure_patterns),
            "expression_variations": len(self.expression_variations),
            "supported_techniques": [
                "ë™ì˜ì–´ êµì²´",
                "ë¬¸ì¥ êµ¬ì¡° ë³€ê²½", 
                "í‘œí˜„ ë‹¤ì–‘í™”",
                "ë¬¸ì¥ ë¶„í• /ê²°í•©",
                "ì–´ìˆœ ë³€ê²½"
            ],
            "effectiveness": "ë†’ìŒ (í‰ê·  15-30% ìœ ì‚¬ë„ ê°ì†Œ)"
        }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    avoidance_system = AIPlagiarismAvoidance()
    
    sample_text = "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì€ í˜„ëŒ€ ì‚¬íšŒì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆë‹¤. ì´ëŸ¬í•œ ê¸°ìˆ ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ íš¨ê³¼ì ì¸ ê²°ê³¼ë¥¼ ì œì‹œí•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ êµìœ¡ ë° ì˜ë£Œ ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆë‹¤."
    
    sample_matches = [
        {
            "matched_text": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì€ í˜„ëŒ€ ì‚¬íšŒì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆë‹¤",
            "start_index": 0,
            "end_index": 35,
            "similarity_score": 85.5
        }
    ]
    
    result = avoidance_system.avoid_plagiarism(sample_text, sample_matches)
    
    print(f"ì›ë³¸: {result.original_text}")
    print(f"ì¬ì‘ì„±: {result.rewritten_text}")
    print(f"ìœ ì‚¬ë„ ê°ì†Œ: {result.similarity_reduction:.1f}%")
    print(f"ì‹ ë¢°ë„: {result.confidence_score:.1f}%")
    print(f"ìˆ˜ì • ì‚¬í•­: {len(result.modifications)}ê°œ")