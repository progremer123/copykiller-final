#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from services.web_crawler_service import WebCrawlerService
from database import get_db

def add_political_content():
    """ì •ì¹˜/ì‹œì‚¬ ê´€ë ¨ ì½˜í…ì¸  ì¶”ê°€"""
    
    crawler = WebCrawlerService()
    
    # ì •ì¹˜/ì‹œì‚¬ ê´€ë ¨ í‚¤ì›Œë“œë“¤
    political_keywords = [
        "ëŒ€í†µë ¹", "ë¯¸êµ­", "í•œë¯¸ê´€ê³„", "ì™¸êµ", "í†µìƒ", 
        "ì •ì¹˜", "ì •ë¶€", "í˜‘ìƒ", "íŠ¸ëŸ¼í”„", "í•œêµ­ì •ì¹˜",
        "êµ­ì œê´€ê³„", "ë¬´ì—­í˜‘ìƒ", "ë™ë§¹", "ì™¸êµì •ì±…", "êµ­ì •"
    ]
    
    print("ğŸ›ï¸ ì •ì¹˜/ì‹œì‚¬ ê´€ë ¨ ì½˜í…ì¸  í¬ë¡¤ë§ ì‹œì‘...")
    
    total_saved = 0
    for keyword in political_keywords:
        try:
            print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
            result = crawler.crawl_and_save(keyword, 3)  # í‚¤ì›Œë“œë‹¹ 3ê°œ ë¬¸ì„œ
            saved_count = result.get('saved_count', 0)
            total_saved += saved_count
            print(f"âœ… '{keyword}': {saved_count}ê°œ ì €ì¥")
            
        except Exception as e:
            print(f"âŒ '{keyword}' í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
    
    print(f"\nğŸ‰ ì´ {total_saved}ê°œì˜ ì •ì¹˜/ì‹œì‚¬ ë¬¸ì„œë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤!")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
    db = next(get_db())
    from models import DocumentSource
    
    total_docs = db.query(DocumentSource).filter(DocumentSource.is_active == True).count()
    print(f"ğŸ“š í˜„ì¬ ì´ í™œì„± ë¬¸ì„œ ìˆ˜: {total_docs}ê°œ")

if __name__ == "__main__":
    add_political_content()